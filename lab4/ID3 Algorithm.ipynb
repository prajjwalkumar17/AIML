{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ec8e034",
   "metadata": {},
   "source": [
    "### ID3 Algorithm Lab Program 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5bdc51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outlook  =>  {'sunny': (3, 2), 'overcast': (0, 4), 'rainy': (2, 3)}\n",
      "overcast  =>  yes\n",
      "temp  =>  {'mild': (1, 2), 'cool': (1, 1)}\n",
      "hot  =>  no\n",
      "cool  =>  yes\n",
      "humidity  =>  {'normal': (1, 1)}\n",
      "high  =>  no\n",
      "normal  =>  yes\n",
      "windy  =>  {'Weak': (0, 1), 'Strong': (1, 0)}\n",
      "Weak  =>  yes\n",
      "Strong  =>  no\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# function to calculate the entropy of entire dataset\n",
    "# -----------------------------------------------------------------------\n",
    "def base_entropy(dataset):\n",
    "    p = 0\n",
    "    n = 0\n",
    "    target = dataset.iloc[:, -1]\n",
    "    targets = list(set(target))\n",
    "    for i in target:\n",
    "        if i == targets[0]:\n",
    "            p = p + 1\n",
    "        else:\n",
    "            n = n + 1\n",
    "    if p == 0 or n == 0:\n",
    "        return 0\n",
    "    elif p == n:\n",
    "        return 1\n",
    "    else:\n",
    "        entropy = 0 - (\n",
    "            ((p / (p + n)) * (math.log2(p / (p + n))) + (n / (p + n)) * (math.log2(n/ (p + n)))))\n",
    "        return entropy\n",
    "\n",
    "# -----------------------------------------------------------------------\n",
    "\n",
    "# function to calculate the entropy of attributes\n",
    "# -----------------------------------------------------------------------\n",
    "def entropy(dataset, feature, attribute):\n",
    "    p = 0\n",
    "    n = 0\n",
    "    target = dataset.iloc[:, -1]\n",
    "    targets = list(set(target))\n",
    "    for i, j in zip(feature, target):\n",
    "        if i == attribute and j == targets[0]:\n",
    "            p = p + 1\n",
    "        elif i == attribute and j == targets[1]:\n",
    "            n = n + 1\n",
    "        if p == 0 or n == 0:\n",
    "            return 0\n",
    "        elif p == n:\n",
    "            return 1\n",
    "        else:\n",
    "            entropy = 0 - (\n",
    "                ((p / (p + n)) * (math.log2(p / (p + n))) + (n / (p + n)) * (math.log2(n/ (p + n)))))\n",
    "            return entropy\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# a utility function for checking purity and impurity of a child\n",
    "# -----------------------------------------------------------------------\n",
    "def counter(target, attribute, i):\n",
    "    p = 0\n",
    "    n = 0\n",
    "    targets = list(set(target))\n",
    "    for j, k in zip(target, attribute):\n",
    "        if j == targets[0] and k == i:\n",
    "            p = p + 1\n",
    "        elif j == targets[1] and k == i:\n",
    "            n = n + 1\n",
    "    return p, n\n",
    "\n",
    "# -----------------------------------------------------------------------\n",
    "# function that calculates the information gain\n",
    "# -----------------------------------------------------------------------\n",
    "def Information_Gain(dataset, feature):\n",
    "    Distinct = list(set(feature))\n",
    "    Info_Gain = 0\n",
    "    for i in Distinct:\n",
    "        Info_Gain = Info_Gain + feature.count(i) / len(feature) * entropy(dataset,feature, i)\n",
    "        Info_Gain = base_entropy(dataset) - Info_Gain\n",
    "    return Info_Gain\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# function that generates the childs of selected Attribute\n",
    "# -----------------------------------------------------------------------\n",
    "def generate_childs(dataset, attribute_index):\n",
    "    distinct = list(dataset.iloc[:, attribute_index])\n",
    "    childs = dict()\n",
    "    for i in distinct:\n",
    "        childs[i] = counter(dataset.iloc[:, -1], dataset.iloc[:, attribute_index], i)\n",
    "    return childs\n",
    "\n",
    "# -----------------------------------------------------------------------\n",
    "\n",
    "# function that modifies the dataset according to the impure childs\n",
    "# -----------------------------------------------------------------------\n",
    "def modify_data_set(dataset,index, feature, impurity):\n",
    "    size = len(dataset)\n",
    "    subdata = dataset[dataset[feature] == impurity]\n",
    "    del (subdata[subdata.columns[index]])\n",
    "    return subdata\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# function that return attribute with the greatest Information Gain\n",
    "# -----------------------------------------------------------------------\n",
    "def greatest_information_gain(dataset):\n",
    "    max = -1\n",
    "    attribute_index = 0\n",
    "    size = len(dataset.columns) - 1\n",
    "    for i in range(0, size):\n",
    "        feature = list(dataset.iloc[:, i])\n",
    "        i_g = Information_Gain(dataset, feature)\n",
    "        if max < i_g:\n",
    "            max = i_g\n",
    "            attribute_index = i\n",
    "    return attribute_index\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# function to construct the decision tree\n",
    "# -----------------------------------------------------------------------\n",
    "def construct_tree(dataset, tree):\n",
    "    target = dataset.iloc[:, -1]\n",
    "    impure_childs = []\n",
    "    attribute_index = greatest_information_gain(dataset)\n",
    "    childs = generate_childs(dataset, attribute_index)\n",
    "    tree[dataset.columns[attribute_index]] = childs\n",
    "    targets = list(set(dataset.iloc[:, -1]))\n",
    "    for k, v in childs.items():\n",
    "        if v[0] == 0:\n",
    "            tree[k] = targets[1]\n",
    "        elif v[1] == 0:\n",
    "            tree[k] = targets[0]\n",
    "        elif v[0] != 0 or v[1] != 0:\n",
    "            impure_childs.append(k)\n",
    "    for i in impure_childs:\n",
    "        sub = modify_data_set(dataset,attribute_index,\n",
    "        dataset.columns[attribute_index], i)\n",
    "        tree = construct_tree(sub, tree)\n",
    "    return tree\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# main function\n",
    "# -----------------------------------------------------------------------\n",
    "def main():\n",
    "    df = pd.read_csv(\"playtennis.csv\")\n",
    "    tree = dict()\n",
    "    result = construct_tree(df, tree)\n",
    "    for key, value in result.items():\n",
    "        print(key, \" => \", value)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
